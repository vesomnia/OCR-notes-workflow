import pathlib
import time
import os
import csv
import logging
import re
from datetime import datetime

# New imports for validation
import matplotlib.pyplot as plt
from matplotlib.mathtext import MathTextParser

from google import genai
from google.api_core import exceptions
from google.genai import types

# 1. Configuration & Global Constants
API_KEY = os.getenv("GEMINI_API_KEY")
TARGET_DIR = pathlib.Path(r"C:\College Notes DATA_BASE")
OUTPUT_DIR = TARGET_DIR / "Transcribed_Text"
FAILURE_LOG_PATH = TARGET_DIR / "conversion_failures.csv"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

if not API_KEY:
    raise EnvironmentError("GEMINI_API_KEY environment variable is not configured.")

client = genai.Client(api_key=API_KEY)

# Ensure the output directory exists
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# --- CORE PROCESSING LOGIC ---

def process_document(pdf_path, output_path, thinking_budget=None):
    """
    Orchestrates high-fidelity transcription using a two-pass verification system.
    """
    myfile = None
    try:
        myfile = client.files.upload(file=pdf_path)

        # Await server-side processing
        start = time.time()
        while myfile.state == "PROCESSING":
            if time.time() - start > 300:
                raise TimeoutError("Server ingestion timeout.")
            time.sleep(5)
            myfile = client.files.get(name=myfile.name)

        if myfile.state == "FAILED":
            raise ValueError("File failed server-side ingestion.")

        # Pass 1: Standard Transcription
        config = types.GenerateContentConfig(
            temperature=0.1,
            thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget) if thinking_budget else None,
            max_output_tokens=8192
        )

        instruction = (
            "SYSTEM: Academic Archivist. Transcribe the multi-page PDF to Markdown. "
            "Use LaTeX for all math. Enclose inline math in single $ and block math in $$. "
            "Label pages clearly with '## Page X'. "
            "Maintain all original headers and bullet points. Literal transcription only."
        )

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[myfile, instruction],
            config=config
        )

        if not response.text:
            raise ValueError("Empty response during transcription.")

        # Pass 2: The Audit Pass (Strict Determinism for Math Syntax)
        audit_instruction = (
            "TASK: Conduct a technical audit of the transcription. "
            "1. Check that all LaTeX equations are syntactically valid (balanced braces, valid commands). "
            "2. Ensure inline math uses single $ and display math uses $$. "
            "3. Correct any 'hallucinated' symbols that do not exist in standard LaTeX. "
            "Return the final, corrected text in full."
        )
        
        verified_response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[myfile, f"DRAFT:\n{response.text}", audit_instruction],
            config=types.GenerateContentConfig(temperature=0.0)
        )

        final_text = verified_response.text if verified_response.text else response.text

        # Atomic File Write
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(final_text)

        return True

    except Exception as e:
        if not isinstance(e, exceptions.ResourceExhausted):
            log_failure(pdf_path.name, "Processing", str(e))
        raise e
    finally:
        if myfile:
            try: client.files.delete(name=myfile.name)
            except: pass

# --- LOGGING & AUDIT TOOLS ---

def log_failure(filename, stage, error_msg):
    file_exists = FAILURE_LOG_PATH.exists()
    with open(FAILURE_LOG_PATH, "a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["timestamp", "file", "stage", "error"])
        if not file_exists: writer.writeheader()
        writer.writerow({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "file": filename, "stage": stage, "error": error_msg
        })

def generate_report():
    all_pdfs = list(TARGET_DIR.glob("*.pdf"))
    failed_files = set()
    if FAILURE_LOG_PATH.exists():
        with open(FAILURE_LOG_PATH, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            failed_files = {row['file'] for row in reader}

    success_count = len(all_pdfs) - len(failed_files)
    rate = (success_count / len(all_pdfs)) * 100 if all_pdfs else 0
    
    print(f"\n--- ACADEMIC BATCH AUDIT ---")
    print(f"Total PDFs: {len(all_pdfs)} | Success: {success_count} | Failures: {len(failed_files)}")
    print(f"Current Efficiency: {rate:.2f}%")
    return failed_files

# --- SYNTAX VALIDATION ENGINE ---

class LaTeXValidator:
    """
    Uses Matplotlib's mathtext parser to strictly validate LaTeX strings.
    If Matplotlib can't parse it, it's likely broken syntax.
    """
    def __init__(self):
        # We use the 'path' backend which is lightweight for parsing checks
        self.parser = MathTextParser('path')

    def is_valid(self, latex_str):
        try:
            # Strip delimiters for the parser check
            clean_str = latex_str.strip("$")
            # Matplotlib requires a non-empty string to parse
            if not clean_str.strip():
                return True 
            self.parser.parse(f"${clean_str}$")
            return True
        except ValueError:
            return False
        except Exception:
            # Catch-all for other MPL rendering errors
            return False

def validate_and_quarantine(output_dir):
    """
    Scans output text files for invalid LaTeX syntax.
    Moves defective files to a '_Review_Required' subdirectory.
    """
    review_dir = output_dir / "_Review_Required"
    flagged_count = 0
    validator = LaTeXValidator()
    
    # Regex to capture content between $...$ or $$...$$
    # This pattern handles standard inline and display math
    latex_pattern = re.compile(r'(\$\$?)(.+?)(\1)', re.DOTALL)
    
    txt_files = list(output_dir.glob("*.txt"))
    
    print(f"\n--- LATEX SYNTAX AUDIT (Powered by Matplotlib) ---")
    
    for txt_file in txt_files:
        is_defective = False
        try:
            with open(txt_file, "r", encoding="utf-8") as f:
                content = f.read()
                
            # 1. Basic Delimiter Check
            if content.count("$") % 2 != 0:
                print(f"[!] SYNTAX ERROR: Uneven delimiters in {txt_file.name}")
                is_defective = True
            
            # 2. Deep Syntax Check via Matplotlib
            else:
                matches = latex_pattern.findall(content)
                for _, equation, _ in matches:
                    if not validator.is_valid(equation):
                        print(f"[!] RENDER FAIL: Invalid LaTeX in {txt_file.name}: {equation[:30]}...")
                        is_defective = True
                        break # One error is enough to quarantine

            if is_defective:
                review_dir.mkdir(parents=True, exist_ok=True)
                target_path = review_dir / txt_file.name
                
                # Move file
                txt_file.rename(target_path)
                flagged_count += 1
                
        except Exception as e:
            logger.error(f"Validation failed for {txt_file.name}: {e}")

    if flagged_count == 0:
        print("Integrity Check Passed: All documents contain valid LaTeX.")
    else:
        print(f"Audit Complete: {flagged_count} files moved to {review_dir}")

# --- MAIN EXECUTION ---

if __name__ == "__main__":
    # Filter: Select PDFs only if their corresponding .txt does NOT exist in the OUTPUT_DIR
    pdf_files = [
        f for f in TARGET_DIR.glob("*.pdf") 
        if not (OUTPUT_DIR / f.with_suffix(".txt").name).exists()
    ]
    
    logger.info(f"Found {len(pdf_files)} documents pending transcription.")

    for pdf in pdf_files:
        output_txt = OUTPUT_DIR / pdf.with_suffix(".txt").name
        
        attempts = 0
        max_attempts = 3
        while attempts < max_attempts:
            try:
                process_document(pdf, output_txt)
                logger.info(f"Success: {pdf.name} -> {output_txt}")
                time.sleep(2) 
                break
            except exceptions.ResourceExhausted:
                wait = (2 ** attempts) * 60 
                logger.warning(f"Rate limited on {pdf.name}. Sleeping {wait}s...")
                time.sleep(wait)
                attempts += 1
            except Exception as e:
                logger.error(f"Critical fail on {pdf.name}: {e}")
                break

    # Final Audit
    failures = generate_report()
    
    # Syntax Integrity & Quarantine
    validate_and_quarantine(OUTPUT_DIR)
